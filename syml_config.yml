'''
CONFIG FILE FOR SKLEARN-BASED
     SYMBOLIC ML MODELING          
'''

# Author   : Filippo Arcadu
# Date     : 09/11/2018



###############################
#                             # 
#             MODEL           #
#                             #
###############################

model:
    # Algorithm name, choose among [ 'rf' , 'xgboost' ]
    algorithm: rf   

    # Metric to select best model, choose among [ 'accuracy' , 'mse' , 'auc' , 'cohen_kappa' ]
    metric: auc

    # Output variable
    col_out: 'NUMEX'

    # Feature columns to select, if "*" is present, the string is used to identify all column
    # names containing it
    select: None

    # Feature columns to exclude, if "*" is present, the string is used to identify all column
    # names containing it
    exclude: None



###############################
#                             # 
#          VALIDATION         #
#                             #
###############################

validation:
    # Data percentage for testing
    testing: 0

    # Name of the column constraining the fold splitting
    col_constr: None

    # Enable K-fold CV
    kfold_cv: True

    # How many folds
    n_folds: 5



###############################
#                             # 
#    RANDOM FOREST PARAMS     #
#                             #
###############################

rf_params:
    # Number of trees on the forest
    n_estimators: 2:40:5

    # Criterion to measure the quality of the split, choose between [ 'entropy' , 'gini' ]
    criterion: [ 'entropy' , 'gini' ]

    # Max depth of a tree
    max_depth: 4:20:4

    # Min number of samples to split an internal node
    min_samples_split: 4

    # Min number of samples to be a leaf node
    min_samples_leaf: 1

    # Use bootstrap when creating trees
    bootstrap: True

    # Use out-of-bag score
    oob_score: True

    # Class weights
    class_weights: 'balanced'



###############################
#                             # 
#        XGBOOST PARAMS       #
#                             #
###############################

xg_params:
    # Which booster to use, choose among [ 'gbtree' , 'dart' ,'gblinear' ],
    # the first two use trees, the third one a linear model
    booster: 'gbtree'

    # Feature dimension used in boosting, set to maximum dimension of the feature 
    num_feature: None

    # Step size shrinkage used in update to prevents overfitting
    eta: 0.3

    # Minimum loss reduction required to make a further partition on a leaf node of the tree
    gamma: 0

    # Maximum depth of a tree. Increasing this value will make the model more complex
    # and more likely to overfit. 0 indicates no limit
    max_depth: 6

    # L2 regularization term on weights. Increasing this value will make model more conservative
    lambda: 1

    # L1 regularization term on weights. Increasing this value will make model more conservative
    alpha: 0

    # The tree construction algorithm used in XGBoost, choose among [ 'auto', 'exact', 'approx', 'hist' ]
    tree_method: 'auto'
