#
# CONFIG FILE FOR SKLEARN-BASED
#     SYMBOLIC ML MODELING          
#
# Author   : Filippo Arcadu
# Date     : 09/11/2018



###############################
#                             # 
#             MODEL           #
#                             #
###############################

model:
    # Algorithm name, choose among [ 'rf-class' , 'rf-regr' , 'xgboost-class' , 'xgboost-regr' ]
    algorithm: rf-class   

    # Metric to select best model, choose among [ 'accuracy' , 'r2' , 'auc' , 'cohen_kappa' ]
    metric: auc

    # Output variable
    col_out: NUMEX-BINARY

    # Feature columns to select
    # Provide the column names individually as a list, e.g. [ 'col_name_01' , 'col_name_02' ]
    # or specify a substring common to all column names to select, e.g. '*pattern*''
    select: None

    # Feature columns to exclude
    # Provide the column names individually as a list, e.g. [ 'col_name_01' , 'col_name_02' ]
    # or specify a substring common to all column names to exclude, e.g. '*pattern*'
    exclude: ['NUMEX']



###############################
#                             # 
#          VALIDATION         #
#                             #
###############################

validation:
    # Data percentage for testing
    testing: 20

    # Name of the column constraining the fold splitting
    col_constr: ANONID

    # Select type of cross-validation, choose among [ None , k-fold , resampling ]
    cv_type: k-fold

    # How many folds
    n_folds: 5



###############################
#                             # 
#    RANDOM FOREST PARAMS     #
#                             #
###############################

rf_params:
    # Number of trees on the forest
    n_estimators: '2:40:5'

    # Criterion to measure the quality of the split, choose between [ 'entropy' , 'gini' ]
    criterion: 'entropy,gini'

    # Max depth of a tree
    max_depth: '4:20:4'

    # Min number of samples to split an internal node
    min_samples_split: 4

    # Min number of samples to be a leaf node
    min_samples_leaf: 1

    # Use bootstrap when creating trees
    bootstrap: True

    # Use out-of-bag score
    oob_score: True

    # Class weights
    class_weight: 'balanced'



###############################
#                             # 
#        XGBOOST PARAMS       #
#                             #
###############################

xg_params:
    # Which booster to use, choose among [ 'gbtree' , 'dart' ,'gblinear' ],
    # the first two use trees, the third one a linear model
    booster: 'gbtree'

    # Feature dimension used in boosting, set to maximum dimension of the feature 
    num_feature: None

    # Step size shrinkage used in update to prevents overfitting
    eta: 0.3

    # Minimum loss reduction required to make a further partition on a leaf node of the tree
    gamma: 0

    # Maximum depth of a tree. Increasing this value will make the model more complex
    # and more likely to overfit. 0 indicates no limit
    max_depth: 6

    # L2 regularization term on weights. Increasing this value will make model more conservative
    lambda: 1

    # L1 regularization term on weights. Increasing this value will make model more conservative
    alpha: 0

    # The tree construction algorithm used in XGBoost, choose among [ 'auto', 'exact', 'approx', 'hist' ]
    tree_method: 'auto'
